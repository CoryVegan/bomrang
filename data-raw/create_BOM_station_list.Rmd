---
title: "Build BoM Station Locations and JSON URL Database"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document provides details on methods used to create the database of BoM JSON files for stations and corresponding metadata, e.g., latitude, longitude (which are more detailed than what is in the JSON file), start, end, elevation, etc.

Refer to these BoM pages for more reference:  
- http://www.bom.gov.au/inside/itb/dm/idcodes/struc.shtml  
- http://reg.bom.gov.au/catalogue/data-feeds.shtml  
- http://reg.bom.gov.au/catalogue/anon-ftp.shtml  
- http://www.bom.gov.au/climate/cdo/about/site-num.shtml  

## Product code definitions
### States
- IDD - NT  
- IDN - NSW/ACT  
- IDQ - Qld
- IDS - SA  
- IDT - Tas/Antarctica (distinguished by the product number)
- IDV - Vic  
- IDW - WA  

### Product code numbers
- 60701 - coastal observations (duplicated in 60801)  
- 60801 - all weather observations (we will use this)  
- 60803 - Antarctica weather observations (and use this, this distinguishes Tas from Antarctica)  
- 60901 - capital city weather observations (duplicated in 60801)  
- 60903 - Canberra area weather observations (duplicated in 60801)  

## Get station metadata

```{r get_bom_station_data, eval=TRUE}

library(magrittr)

# This file is a pseudo-fixed width file. Line five contains the headers at
# fixed widths which are coded in the read_table() call.
# The last six lines contain other information that we don't want.
# For some reason, reading it directly from the BoM website does not work, so
# we use download.file to fetch it first and then import it from the R tempdir()

  curl::curl_download(url = "ftp://ftp.bom.gov.au/anon2/home/ncc/metadata/sitelists/stations.zip",
                      destfile = paste0(tempdir(), "stations.zip"))

  bom_stations_raw <-
    readr::read_table(
      paste0(tempdir(), "stations.zip"),
      skip = 5,
      guess_max = 20000,
      col_names = c(
        "site",
        "dist",
        "name",
        "start",
        "end",
        "Lat",
        "Lon",
        "source",
        "state",
        "elev",
        "bar_ht",
        "WMO"
      ),
      col_types = readr::cols(
        site = readr::col_character(),
        dist = readr::col_character(),
        name = readr::col_character(),
        start = readr::col_integer(),
        end = readr::col_integer(),
        Lat = readr::col_double(),
        Lon = readr::col_double(),
        source = readr::col_character(),
        state = readr::col_character(),
        elev = readr::col_double(),
        bar_ht = readr::col_double(),
        WMO = readr::col_integer()
      ),
      na = c("..")
    )

  # trim the end of the rows off that have extra info that's not in columns
  nrows <- nrow(bom_stations_raw) - 5
  bom_stations_raw <- bom_stations_raw[1:nrows, ]

  # recode the states to match product codes
  # IDD - NT, IDN - NSW/ACT, IDQ - Qld, IDS - SA, IDT - Tas/Antarctica, IDV - Vic, IDW - WA

  bom_stations_raw$state_code <- NA
  bom_stations_raw$state_code[bom_stations_raw$state == "WA"] <-
    "W"
  bom_stations_raw$state_code[bom_stations_raw$state == "QLD"] <-
    "Q"
  bom_stations_raw$state_code[bom_stations_raw$state == "VIC"] <-
    "V"
  bom_stations_raw$state_code[bom_stations_raw$state == "NT"] <-
    "D"
  bom_stations_raw$state_code[bom_stations_raw$state == "TAS" |
                                bom_stations_raw$state == "ANT"] <-
    "T"
  bom_stations_raw$state_code[bom_stations_raw$state == "NSW"] <-
    "N"
  bom_stations_raw$state_code[bom_stations_raw$state == "SA"] <-
    "S"

  stations_site_list <-
    bom_stations_raw %>%
    dplyr::select(site:name, dplyr::everything()) %>%
    dplyr::mutate(
      url = dplyr::case_when(
        .$state != "ANT" & !is.na(.$WMO) ~
          paste0(
            "http://www.bom.gov.au/fwo/ID",
            .$state_code,
            "60801",
            "/",
            "ID",
            .$state_code,
            "60801",
            ".",
            .$WMO,
            ".json"
          ),
        .$state == "ANT" & !is.na(.$WMO) ~
          paste0(
            "http://www.bom.gov.au/fwo/ID",
            .$state_code,
            "60803",
            "/",
            "ID",
            .$state_code,
            "60803",
            ".",
            .$WMO,
            ".json"
          )
      )
    )

  # return only current stations listing
  stations_site_list <-
  stations_site_list[is.na(stations_site_list$end),]
  stations_site_list$end <- format(Sys.Date(), "%Y")

stations_site_list
```
## Save data
Now that we have the dataframe of stations and have generated the URLs for the JSON files for stations providing weather data feeds, save the data as a database for _bomrang_ to use.

There are weather stations that do have a WMO but don't report online, e.g., KIRIBATI NTC AWS or MARSHALL ISLANDS NTC AWS, in this section remove these from the list and then create a database for use with the current weather information from BoM.

### Save JSON URL database for `get_current_weather()`

```{r save_url_data, eval=TRUE, message=FALSE}
JSONurl_latlon_by_station_name <-
  stations_site_list[!is.na(stations_site_list$url), ]

JSONurl_latlon_by_station_name <-
  JSONurl_latlon_by_station_name %>%
  dplyr::rowwise() %>%
  dplyr::mutate(url = dplyr::if_else(httr::http_error(url), NA_character_, url))
  
# Remove new NA values from invalid URLs and convert to data.table
JSONurl_latlon_by_station_name <-
  data.table::data.table(stations_site_list[!is.na(stations_site_list$url), ])
  
# Save database
devtools::use_data(JSONurl_latlon_by_station_name, overwrite = TRUE)
```

### Save station location data for `get_ag_bulletin()`

First, rename columns and drop a few that aren't necessary for the ag bulletin information. Then pad the `site` field with 0 to match the data in the XML file that holds the bulletin information.

Lastly, create the database for use in the package.

```{r save_location_data, eval=TRUE, message=FALSE}
stations_site_list <-
  stations_site_list %>%
  dplyr::rename(lat = Lat,
  lon = Lon) %>%
  dplyr::select(-state_code, -source, -url)

stations_site_list$site <-
  gsub("^0{1,2}", "", stations_site_list$site)

devtools::use_data(stations_site_list, overwrite = TRUE)
```

## Session Info
```{r session_info, echo=FALSE}
devtools::session_info()
```
